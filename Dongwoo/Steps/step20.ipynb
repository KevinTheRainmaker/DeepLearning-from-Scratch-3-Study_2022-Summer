{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c294be81",
   "metadata": {},
   "source": [
    "# Step 20 Operator Overloading(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee15c2",
   "metadata": {},
   "source": [
    "## 20.1 Implementation of Mul class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8378e00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Codes/step19.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6521090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mul(Function):\n",
    "    def forward(self, x0,x1):\n",
    "        y=x0*x1\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        x0,x1=self.inputs[0].data, self.inputs[1].data\n",
    "        return gy*x1, gy*x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac69b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul(x0,x1):\n",
    "    return Mul()(x0,x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d4cf186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(7.0)\n",
      "2.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "a=Variable(np.array(3.0))\n",
    "b=Variable(np.array(2.0))\n",
    "c=Variable(np.array(1.0))\n",
    "\n",
    "y=add(mul(a,b),c)\n",
    "y.backward()\n",
    "print(y)\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb82cb7",
   "metadata": {},
   "source": [
    "## 20.2 Operator Overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6fc28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import weakref\n",
    "import contextlib\n",
    "\n",
    "class Config:\n",
    "    enable_backprop=True\n",
    "\n",
    "@contextlib.contextmanager #decorator to understand the context\n",
    "    \n",
    "def using_config(name, value):\n",
    "    old_value=getattr(Config, name)\n",
    "    setattr(Config, name, value)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        setattr(Config, name, old_value)    \n",
    "\n",
    "def no_grad():\n",
    "    return using_config('enable_backprop', False)\n",
    "        \n",
    "class Variable:\n",
    "    def __init__(self, data, name=None): #added name=None\n",
    "        if data is not None:\n",
    "            if not isinstance(data, np.ndarray):\n",
    "                raise TypeError('{} is not supported'.format(type(data)))\n",
    "        \n",
    "        self.name=name #added\n",
    "        self.data = data\n",
    "        self.grad = None\n",
    "        self.creator = None\n",
    "        self.generation=0\n",
    "\n",
    "    def set_creator(self, func):\n",
    "        self.creator = func\n",
    "        self.generation= func.generation+1 \n",
    "\n",
    "    def backward(self, retain_grad=False):\n",
    "        if self.grad is None:\n",
    "            self.grad = np.ones_like(self.data)\n",
    "\n",
    "        funcs = []\n",
    "        seen_set=set()\n",
    "        \n",
    "        def add_func(f):\n",
    "            if f not in seen_set:\n",
    "                funcs.append(f)\n",
    "                seen_set.add(f)\n",
    "                funcs.sort(key=lambda x: x.generation)\n",
    "        add_func(self.creator)\n",
    "        \n",
    "        while funcs:\n",
    "            f = funcs.pop()\n",
    "            gys = [output().grad for output in f.outputs] \n",
    "            gxs = f.backward(*gys) \n",
    "            if not isinstance(gxs, tuple): \n",
    "                gxs=(gxs, )\n",
    "            for x, gx in zip(f.inputs, gxs): \n",
    "                if x.grad is None:\n",
    "                    x.grad=gx\n",
    "                else:\n",
    "                    x.grad=x.grad+gx \n",
    "            \n",
    "                if x.creator is not None:\n",
    "                    add_func(x.creator)\n",
    "            \n",
    "            if not retain_grad:\n",
    "                for y in f.outputs:\n",
    "                    y().grad=None\n",
    "    def cleargrad(self):\n",
    "        self.grad=None\n",
    "    \n",
    "    @property\n",
    "    def ndim(self):\n",
    "        return self.data.ndim\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.data.size\n",
    "    \n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.data.dtype\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __repr__(self): #print out the data inside Variable\n",
    "        if self.data is None:\n",
    "            return 'variable(None)'\n",
    "        p=str(self.data).replace('\\n','\\n'+''*9)\n",
    "        return 'variable('+p+')'\n",
    "    \n",
    "    def __mul__(self, other): #Overloading the multiplication operator *\n",
    "        return mul(self, other)\n",
    "\n",
    "def as_array(x):\n",
    "    if np.isscalar(x):\n",
    "        return np.array(x)\n",
    "    return x\n",
    "\n",
    "class Function:\n",
    "    def __call__(self, *inputs):\n",
    "        xs = [x.data for x in inputs]\n",
    "        ys = self.forward(*xs)\n",
    "        if not isinstance(ys, tuple):\n",
    "            ys = (ys,)\n",
    "        outputs = [Variable(as_array(y)) for y in ys]\n",
    "        \n",
    "        if Config.enable_backprop:\n",
    "            self.generation=max([x.generation for x in inputs])         \n",
    "            for output in outputs:\n",
    "                output.set_creator(self)\n",
    "            self.inputs = inputs\n",
    "            self.outputs=[weakref.ref(output) for output in outputs] \n",
    "        return outputs if len(outputs) > 1 else outputs[0]\n",
    "\n",
    "    def forward(self, xs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def backward(self, gys):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "class Add(Function):\n",
    "    def forward(self, x0, x1):\n",
    "        y=x0+x1\n",
    "        return y\n",
    "    def backward(self, gy):\n",
    "        return gy, gy\n",
    "\n",
    "def add(x0, x1):\n",
    "    return Add()(x0, x1)    \n",
    "    \n",
    "class Square(Function):\n",
    "    def forward(self, x):\n",
    "        y=x**2\n",
    "        return y\n",
    "    def backward(self, gy):\n",
    "        x=self.inputs[0].data # prev: x=self.input.data\n",
    "        gx=2*x*gy\n",
    "        return gx\n",
    "\n",
    "def square(x):\n",
    "    return Square()(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47954524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(6.0)\n"
     ]
    }
   ],
   "source": [
    "a=Variable(np.array(3.0))\n",
    "b=Variable(np.array(2.0))\n",
    "y=a*b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b78a6",
   "metadata": {},
   "source": [
    "__a__, __b__ corresponds to __self__ and __other__ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e53486aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import weakref\n",
    "import contextlib\n",
    "\n",
    "class Config:\n",
    "    enable_backprop=True\n",
    "\n",
    "@contextlib.contextmanager #decorator to understand the context\n",
    "    \n",
    "def using_config(name, value):\n",
    "    old_value=getattr(Config, name)\n",
    "    setattr(Config, name, value)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        setattr(Config, name, old_value)    \n",
    "\n",
    "def no_grad():\n",
    "    return using_config('enable_backprop', False)\n",
    "        \n",
    "class Variable:\n",
    "    def __init__(self, data, name=None): #added name=None\n",
    "        if data is not None:\n",
    "            if not isinstance(data, np.ndarray):\n",
    "                raise TypeError('{} is not supported'.format(type(data)))\n",
    "        \n",
    "        self.name=name #added\n",
    "        self.data = data\n",
    "        self.grad = None\n",
    "        self.creator = None\n",
    "        self.generation=0\n",
    "\n",
    "    def set_creator(self, func):\n",
    "        self.creator = func\n",
    "        self.generation= func.generation+1 \n",
    "\n",
    "    def backward(self, retain_grad=False):\n",
    "        if self.grad is None:\n",
    "            self.grad = np.ones_like(self.data)\n",
    "\n",
    "        funcs = []\n",
    "        seen_set=set()\n",
    "        \n",
    "        def add_func(f):\n",
    "            if f not in seen_set:\n",
    "                funcs.append(f)\n",
    "                seen_set.add(f)\n",
    "                funcs.sort(key=lambda x: x.generation)\n",
    "        add_func(self.creator)\n",
    "        \n",
    "        while funcs:\n",
    "            f = funcs.pop()\n",
    "            gys = [output().grad for output in f.outputs] \n",
    "            gxs = f.backward(*gys) \n",
    "            if not isinstance(gxs, tuple): \n",
    "                gxs=(gxs, )\n",
    "            for x, gx in zip(f.inputs, gxs): \n",
    "                if x.grad is None:\n",
    "                    x.grad=gx\n",
    "                else:\n",
    "                    x.grad=x.grad+gx \n",
    "            \n",
    "                if x.creator is not None:\n",
    "                    add_func(x.creator)\n",
    "            \n",
    "            if not retain_grad:\n",
    "                for y in f.outputs:\n",
    "                    y().grad=None\n",
    "    def cleargrad(self):\n",
    "        self.grad=None\n",
    "    \n",
    "    @property\n",
    "    def ndim(self):\n",
    "        return self.data.ndim\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.data.size\n",
    "    \n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.data.dtype\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __repr__(self): #print out the data inside Variable\n",
    "        if self.data is None:\n",
    "            return 'variable(None)'\n",
    "        p=str(self.data).replace('\\n','\\n'+''*9)\n",
    "        return 'variable('+p+')'\n",
    "    \n",
    "    def __mul__(self, other): #Overloading the multiplication operator *\n",
    "        return mul(self, other)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return add(self, other)\n",
    "    \n",
    "    Variable.__mul__=mul\n",
    "    Variable.__add__=add\n",
    "\n",
    "def as_array(x):\n",
    "    if np.isscalar(x):\n",
    "        return np.array(x)\n",
    "    return x\n",
    "\n",
    "class Function:\n",
    "    def __call__(self, *inputs):\n",
    "        xs = [x.data for x in inputs]\n",
    "        ys = self.forward(*xs)\n",
    "        if not isinstance(ys, tuple):\n",
    "            ys = (ys,)\n",
    "        outputs = [Variable(as_array(y)) for y in ys]\n",
    "        \n",
    "        if Config.enable_backprop:\n",
    "            self.generation=max([x.generation for x in inputs])         \n",
    "            for output in outputs:\n",
    "                output.set_creator(self)\n",
    "            self.inputs = inputs\n",
    "            self.outputs=[weakref.ref(output) for output in outputs] \n",
    "        return outputs if len(outputs) > 1 else outputs[0]\n",
    "\n",
    "    def forward(self, xs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def backward(self, gys):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "class Add(Function):\n",
    "    def forward(self, x0, x1):\n",
    "        y=x0+x1\n",
    "        return y\n",
    "    def backward(self, gy):\n",
    "        return gy, gy\n",
    "\n",
    "def add(x0, x1):\n",
    "    return Add()(x0, x1)    \n",
    "    \n",
    "class Square(Function):\n",
    "    def forward(self, x):\n",
    "        y=x**2\n",
    "        return y\n",
    "    def backward(self, gy):\n",
    "        x=self.inputs[0].data # prev: x=self.input.data\n",
    "        gx=2*x*gy\n",
    "        return gx\n",
    "\n",
    "def square(x):\n",
    "    return Square()(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "508eba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(7.0)\n",
      "2.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "a=Variable(np.array(3.0))\n",
    "b=Variable(np.array(2.0))\n",
    "c=Variable(np.array(1.0))\n",
    "y=a*b+c\n",
    "y.backward()\n",
    "print(y)\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
